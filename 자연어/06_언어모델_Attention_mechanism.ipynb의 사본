{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oA64gWw1CpnVN1oPpW8m77xAK79O5O40","timestamp":1682903433053}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZPjBT54oh1G"},"outputs":[],"source":["# 어텐션 메커니즘 \n","# 가중치 계산 \n","# query vector, keys vectors 유사도 기반 내적 계산 >> attention sccore \n","# softmax 함수 이용, 가중치 계산 \n","# keys vector 에 가중평균 적용 >> context vector 생성 \n","# query 와 keys 를 입력으로 이용 "]},{"cell_type":"code","source":["import numpy as np \n","\n","# 나는 집에 -> 갑니다 (2차원 벡터) >> 1차원 벡터 \n","\n","# 입력문장에 대한 hidden state : keys \n","\n","keys = np.array([[0.11, 0.12, 0.13],   # 나는\n","                 [0.21,0.22,0.23]])    # 집에 \n","\n","\n","# 현재 출력 시점에서의 hidden state : query \n","\n","query = np.array([0.41, 0.42, 0.43])  # 갑니다 \n","\n","print(keys.shape, query.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJ-PiX9RpaNF","outputId":"856b02de-c684-4d3f-fbc8-5cb8de15830a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 3) (3,)\n"]}]},{"cell_type":"code","source":["# 어테션 메커니즘 \n","\n","# 1. attention score 계산(유사도 반영)\n","\n","scores = np.dot(keys, query)\n","\n","print(scores, scores.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NitqZTaap6UI","outputId":"20246256-32a5-4152-f264-3049ff081f11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.1514 0.2774] (2,)\n"]}]},{"cell_type":"code","source":["# 2. Attention weights 계산(softmax) >> 중요도 계산 \n","\n","np.exp(scores) / np.sum(np.exp(scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fe92_MoGqKyT","outputId":"41afe16b-26ae-41f1-ce6a-dc3458fa809a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.46854161, 0.53145839])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["weights= np.exp(scores) / np.sum(np.exp(scores))\n","\n","weights.repeat(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpzjPLreqbLY","outputId":"af8fd743-9723-438c-e8fc-56be7aa9b48f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.46854161, 0.46854161, 0.46854161, 0.53145839, 0.53145839,\n","       0.53145839])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["weights.repeat(3).reshape(2,3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmXoUUgnqj6S","outputId":"3d794a6e-b21b-4a57-949c-ef50392260e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.46854161, 0.46854161, 0.46854161],\n","       [0.53145839, 0.53145839, 0.53145839]])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["weights_repeated = weights.repeat(3).reshape(2,3)"],"metadata":{"id":"6VMKtJtcqpvC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keys"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wu_syffgqvKC","outputId":"8ec76a07-2a10-47fc-c861-3f8fcc4f1349"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.11, 0.12, 0.13],\n","       [0.21, 0.22, 0.23]])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# 가중평균 계산 \n","\n","keys * weights_repeated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VXLpqQnqxKy","outputId":"6a9bb92f-5922-4724-ee27-8a1913028354"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.05153958, 0.05622499, 0.06091041],\n","       [0.11160626, 0.11692085, 0.12223543]])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["context_vector = keys * weights_repeated\n","print('context_vector:', context_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7w0z4YXq3eo","outputId":"024a0a80-a854-451f-a2d5-7a5f591be175"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["context_vector: [[0.05153958 0.05622499 0.06091041]\n"," [0.11160626 0.11692085 0.12223543]]\n"]}]},{"cell_type":"code","source":["context_vector.sum(axis=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtA7N8dkq-0P","outputId":"5ec8c01a-648c-4d6c-8c21-b3e9e6be887b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.16314584, 0.17314584, 0.18314584])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["context_vector = context_vector.sum(axis=0)\n","context_vector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RQGEtLFrLdy","outputId":"d87e42ee-03cb-4a12-dde4-7af9e3719def"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.16314584, 0.17314584, 0.18314584])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["# 셀프 어텐션 (Self-Attention)\n","\n","# 하나의 문장 또는 문서에서 단어 간 상호작용을 모델링 하기 위해 사용하는 어텐션 메커니즘 \n","\n","# 셀프 어텐션 구현 단계\n","# 1. 임베딩 층을 통해 입력 문장을 임베딩 벡터로 변환 \n","# 2. 입력 임베딩 벡터 >> query , key, value 구분해서 나눔 \n","# 3. 각각을 query, keys, values 변수에 저장 \n","# 4. query와 key 내적,  어텐션 스코어(attention score) 계산 \n","# 5. 어텐션 스코어에 softmax 함수 적용 >> (전체의 합이 1인 확률값 변환) >> 가중치(weights) 계산산\n","# 6. 가중치(weights)와 value 곱하여 컨텍스트 벡터 (context vector) 계산 "],"metadata":{"id":"rEsf-_xArRQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np \n","\n","def self_attention(inputs): \n","  # inputs : [batch_size, seq_len, d_model]\n","  \n","  # query, key, value 생성 \n","  # 실제 q, k, v 입력값은 다름(편의상 같은 값 입력값으로 사용)\n","\n","  q = inputs\n","  k = inputs\n","  v = inputs \n","\n","  # 1. 행렬 곱(내적) >> attention score 계산 \n","  scores = np.matmul(q, k.transpose(0,2,1))\n","\n","  # 2. 스케일링(scaled) 작업 \n","  d_k = q.shape[-1]\n","  scores /= np.sqrt(d_k)\n"," \n","  # 3. softmax 함수 적용, 가중치 계산 \n","  weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n","\n","  # 4. 가중치(weights)와 values 를 곱함(내적) >> context vector 계산 \n","  context_vector = np.matmul(weights, v)\n","\n","  return context_vector"],"metadata":{"id":"AL6r5-AJsq-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 입력문장에 대한 hidden state : keys \n","\n","inputs = np.array([[[0.11, 0.12, 0.13],   # 나는\n","                   [0.21, 0.22, 0.23],   # 집에       \n","                   [0.31, 0.32, 0.33]]])  # 갑니다   "],"metadata":{"id":"ByiQAnrEsytY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Afzp2MTgv5sA","outputId":"45e0c86d-631f-4e2e-cc4f-2f0b5856cde4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 3, 3)"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["self_attention(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATUGbtcgv8Bl","outputId":"900f9582-4081-49e5-cb85-e008095d5ed0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.21138554, 0.22138554, 0.23138554],\n","        [0.21253973, 0.22253973, 0.23253973],\n","        [0.21369315, 0.22369315, 0.23369315]]])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["context_vector = self_attention(inputs)\n","print('context_vector:', context_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaCAzJAfwUk6","outputId":"f9da7ece-f114-4899-d93a-29f45e4ed57e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["context_vector: [[[0.21138554 0.22138554 0.23138554]\n","  [0.21253973 0.22253973 0.23253973]\n","  [0.21369315 0.22369315 0.23369315]]]\n"]}]},{"cell_type":"code","source":["# Multi-Head attention \n","\n","import tensorflow as tf \n","\n","# 입력문장을 임베딩 한 후, 셀프 어텐션을 수행하는 함수 \n","\n","def multi_head_attention(embeddings): \n","  # 셀프어텐션 수행 \n","  attention_output = tf.keras.layers.MultiHeadAttention(\n","      num_heads=8, key_dim=512)(embeddings, embeddings)\n","\n","  # 셀프어텐션 출력값 >> 임베딩벡터에 더함 >> 최종 출력값 생성 \n","  add_output = tf.keras.layers.Add()([attention_output, embeddings])\n","\n","  # 출력값을 정규화 \n","  normalization_output = tf.keras.layers.LayerNormalization()(add_output)\n","\n","  return normalization_output"],"metadata":{"id":"X-E2PzJlwdo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예시 입력문장\n","\n","inputs = tf.keras.layers.Input(shape=(10, 512))\n","\n","# 입력 임베딩\n","embeddings = tf.keras.layers.Embedding(input_dim=10000, output_dim=512)(inputs)\n","\n","# 멀티 헤더 어텐션 수행 \n","attention_output = multi_head_attention(embeddings)\n","attention_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nsStTKwzD5V","outputId":"73c6b225-0557-4699-aeaa-a4e4565c5e22"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 10, 512, 512) dtype=float32 (created by layer 'layer_normalization')>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":[],"metadata":{"id":"ooAXubShzD8D"},"execution_count":null,"outputs":[]}]}
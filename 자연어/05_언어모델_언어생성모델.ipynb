{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MX5SFYSbCfCx"
      },
      "outputs": [],
      "source": [
        "#아주 간단한 언어생성모델 with RNN\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "from keras.utils import to_categorical #원학인코딩"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예시 훈련 데이터\n",
        "text = '오늘 우리는 언어모델을 공부했어요. 수업이 끝났습니다. 나는 집에 갑니다. 다음에 또 만나요.'"
      ],
      "metadata": {
        "id": "qtlP_2pgDqfh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문지ㅏ와ㅣ 인덷ㄱ스를 매핑>딕셔너리 생성 (단어사전ㄴ생성)\n",
        "#문자단위 (char 단위)\n",
        "\n",
        "chars = sorted(list(set(text))) #중복제거 후 리스트로 변환\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXAnnDbCD7CY",
        "outputId": "57624836-f56f-4f24-d2de-8ecb3af10042"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '.', '갑', '공', '끝', '나', '났', '는', '늘', '니', '다', '델', '또', '리', '만', '모', '부', '수', '습', '어', '언', '업', '에', '오', '요', '우', '을', '음', '이', '집', '했']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#정수 인코딩 <-> 문자로 변환\n",
        "\n",
        "print( {char : idx for idx, char in enumerate(chars)} )\n",
        "print( {idx : char for idx, char in enumerate(chars)} )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3RdX2hdEKAA",
        "outputId": "e19d4cb1-8352-4989-ab93-bd74f869fa23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, '.': 1, '갑': 2, '공': 3, '끝': 4, '나': 5, '났': 6, '는': 7, '늘': 8, '니': 9, '다': 10, '델': 11, '또': 12, '리': 13, '만': 14, '모': 15, '부': 16, '수': 17, '습': 18, '어': 19, '언': 20, '업': 21, '에': 22, '오': 23, '요': 24, '우': 25, '을': 26, '음': 27, '이': 28, '집': 29, '했': 30}\n",
            "{0: ' ', 1: '.', 2: '갑', 3: '공', 4: '끝', 5: '나', 6: '났', 7: '는', 8: '늘', 9: '니', 10: '다', 11: '델', 12: '또', 13: '리', 14: '만', 15: '모', 16: '부', 17: '수', 18: '습', 19: '어', 20: '언', 21: '업', 22: '에', 23: '오', 24: '요', 25: '우', 26: '을', 27: '음', 28: '이', 29: '집', 30: '했'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_idx = {char : idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx : char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "mc4tS0GwErDA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee-VxIi4E9Fw",
        "outputId": "d1b826f0-a87b-45dc-e8fa-737dda1bad42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voca_size=len(chars)\n",
        "print('voca_size : ', voca_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgQ3bKFoFLtw",
        "outputId": "c8d33943-c699-4e2c-f0bd-f704d00be9ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "voca_size :  31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 전처리\n",
        "#하이퍼 파라미터 : 문장의 길이 생성\n",
        "\n",
        "seq_length = 5\n",
        "\n",
        "#데이터 전처리 \n",
        "input_data = []\n",
        "target_data = []\n",
        "\n",
        "for i in range(len(text) - seq_length): \n",
        "    #전체 문장 중에서 seq_length(5개)씩 빼서 for loop 돌리기\n",
        "    input_seq = text[i: i+seq_length]\n",
        "    target_char = text[i + seq_length]\n",
        "\n",
        "    input_data.append([char_to_idx[char] for char in input_seq])\n",
        "    target_data.append(char_to_idx[target_char])\n",
        "\n",
        "input_data=np.array(input_data)\n",
        "target_data=to_categorical(target_data, num_classes=len(chars))"
      ],
      "metadata": {
        "id": "Pn2pfsJtFT8Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('입력 형태: ', input_data.shape)\n",
        "#성분의 개수 : 48, 5개의 단어 (char) 단위"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcSNI80SIUmY",
        "outputId": "9c6fa283-e3c1-4c48-a637-ca933525f8cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 형태:  (47, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KiHptTcG4QI",
        "outputId": "87d52c6d-4ada-4766-a945-074e3e8a73f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('출력 형태: ', target_data.shape)\n",
        "#31개로 다중분류"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoyasICUIfKf",
        "outputId": "3b2369b5-457b-4687-85fc-7fe6ae9e94bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "출력 형태:  (47, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHO9lDTcGibO",
        "outputId": "45bf48e4-f5cf-49b4-83b8-97bd013ca4a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23,  8,  0, 25, 13],\n",
              "       [ 8,  0, 25, 13,  7],\n",
              "       [ 0, 25, 13,  7,  0],\n",
              "       [25, 13,  7,  0, 20],\n",
              "       [13,  7,  0, 20, 19],\n",
              "       [ 7,  0, 20, 19, 15],\n",
              "       [ 0, 20, 19, 15, 11],\n",
              "       [20, 19, 15, 11, 26],\n",
              "       [19, 15, 11, 26,  0],\n",
              "       [15, 11, 26,  0,  3],\n",
              "       [11, 26,  0,  3, 16],\n",
              "       [26,  0,  3, 16, 30],\n",
              "       [ 0,  3, 16, 30, 19],\n",
              "       [ 3, 16, 30, 19, 24],\n",
              "       [16, 30, 19, 24,  1],\n",
              "       [30, 19, 24,  1,  0],\n",
              "       [19, 24,  1,  0, 17],\n",
              "       [24,  1,  0, 17, 21],\n",
              "       [ 1,  0, 17, 21, 28],\n",
              "       [ 0, 17, 21, 28,  0],\n",
              "       [17, 21, 28,  0,  4],\n",
              "       [21, 28,  0,  4,  6],\n",
              "       [28,  0,  4,  6, 18],\n",
              "       [ 0,  4,  6, 18,  9],\n",
              "       [ 4,  6, 18,  9, 10],\n",
              "       [ 6, 18,  9, 10,  1],\n",
              "       [18,  9, 10,  1,  0],\n",
              "       [ 9, 10,  1,  0,  5],\n",
              "       [10,  1,  0,  5,  7],\n",
              "       [ 1,  0,  5,  7,  0],\n",
              "       [ 0,  5,  7,  0, 29],\n",
              "       [ 5,  7,  0, 29, 22],\n",
              "       [ 7,  0, 29, 22,  0],\n",
              "       [ 0, 29, 22,  0,  2],\n",
              "       [29, 22,  0,  2,  9],\n",
              "       [22,  0,  2,  9, 10],\n",
              "       [ 0,  2,  9, 10,  1],\n",
              "       [ 2,  9, 10,  1,  0],\n",
              "       [ 9, 10,  1,  0, 10],\n",
              "       [10,  1,  0, 10, 27],\n",
              "       [ 1,  0, 10, 27, 22],\n",
              "       [ 0, 10, 27, 22,  0],\n",
              "       [10, 27, 22,  0, 12],\n",
              "       [27, 22,  0, 12,  0],\n",
              "       [22,  0, 12,  0, 14],\n",
              "       [ 0, 12,  0, 14,  5],\n",
              "       [12,  0, 14,  5, 24]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT_5f4OZGsEA",
        "outputId": "f497c4b2-9bf9-4378-fe2e-6a7a0e86af86"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpdXz7ZHGtig",
        "outputId": "76955b38-11c8-4d06-c207-4df159d9b957"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23,  8,  0, 25, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('첫번째 입력 데이터 sequence: ', input_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKoSdIiBI_Ef",
        "outputId": "d194e619-be8a-457a-c641-9f45741a8f73"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 입력 데이터 sequence:  [23  8  0 25 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ idx_to_char[idx] for idx in input_data[0] ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYpSssiCIsTI",
        "outputId": "f2c0a581-615a-4165-af9e-4699fd0c6848"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['오', '늘', ' ', '우', '리']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('정답 데이터', target_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce5b6LVBIvZA",
        "outputId": "e60d5ec5-3f58-4044-9e90-92ad8e625be1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 데이터 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델링 및 학습\n",
        "#모델 생성\n",
        "\n",
        "model=Sequential()\n",
        "model.add(SimpleRNN(64, input_shape=(seq_length,1), activation='tanh'))\n",
        "model.add(Dense(voca_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "Ak2NNsdJJLvw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 컴파일(다중분류)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xaXQLYeaJthG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 학습\n",
        "model.fit(input_data, target_data, epochs=200, batch_size=1, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHl1XNwrKBGg",
        "outputId": "4f65a3f5-f673-4fcd-b043-aac453414ac3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 - 6s - loss: 3.6622 - accuracy: 0.0000e+00 - 6s/epoch - 123ms/step\n",
            "Epoch 2/200\n",
            "47/47 - 0s - loss: 3.0218 - accuracy: 0.1702 - 165ms/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "47/47 - 0s - loss: 2.7665 - accuracy: 0.2340 - 159ms/epoch - 3ms/step\n",
            "Epoch 4/200\n",
            "47/47 - 0s - loss: 2.6196 - accuracy: 0.2340 - 161ms/epoch - 3ms/step\n",
            "Epoch 5/200\n",
            "47/47 - 0s - loss: 2.4751 - accuracy: 0.2766 - 155ms/epoch - 3ms/step\n",
            "Epoch 6/200\n",
            "47/47 - 0s - loss: 2.3642 - accuracy: 0.2553 - 148ms/epoch - 3ms/step\n",
            "Epoch 7/200\n",
            "47/47 - 0s - loss: 2.2505 - accuracy: 0.2979 - 186ms/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "47/47 - 0s - loss: 2.1519 - accuracy: 0.3617 - 175ms/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "47/47 - 0s - loss: 2.0798 - accuracy: 0.3191 - 158ms/epoch - 3ms/step\n",
            "Epoch 10/200\n",
            "47/47 - 0s - loss: 1.9958 - accuracy: 0.3617 - 175ms/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "47/47 - 0s - loss: 1.9029 - accuracy: 0.4255 - 160ms/epoch - 3ms/step\n",
            "Epoch 12/200\n",
            "47/47 - 0s - loss: 1.8540 - accuracy: 0.4255 - 160ms/epoch - 3ms/step\n",
            "Epoch 13/200\n",
            "47/47 - 0s - loss: 1.7656 - accuracy: 0.4681 - 171ms/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "47/47 - 0s - loss: 1.6842 - accuracy: 0.4681 - 173ms/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "47/47 - 0s - loss: 1.6270 - accuracy: 0.4894 - 156ms/epoch - 3ms/step\n",
            "Epoch 16/200\n",
            "47/47 - 0s - loss: 1.5717 - accuracy: 0.5319 - 179ms/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "47/47 - 0s - loss: 1.5142 - accuracy: 0.5957 - 171ms/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "47/47 - 0s - loss: 1.4292 - accuracy: 0.6170 - 159ms/epoch - 3ms/step\n",
            "Epoch 19/200\n",
            "47/47 - 0s - loss: 1.3669 - accuracy: 0.5957 - 168ms/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "47/47 - 0s - loss: 1.3341 - accuracy: 0.6383 - 172ms/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "47/47 - 0s - loss: 1.2719 - accuracy: 0.6170 - 157ms/epoch - 3ms/step\n",
            "Epoch 22/200\n",
            "47/47 - 0s - loss: 1.2145 - accuracy: 0.7021 - 389ms/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "47/47 - 0s - loss: 1.1534 - accuracy: 0.8085 - 251ms/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "47/47 - 0s - loss: 1.1029 - accuracy: 0.7447 - 169ms/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "47/47 - 0s - loss: 1.0645 - accuracy: 0.7660 - 156ms/epoch - 3ms/step\n",
            "Epoch 26/200\n",
            "47/47 - 0s - loss: 1.0071 - accuracy: 0.7447 - 174ms/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "47/47 - 0s - loss: 0.9705 - accuracy: 0.7447 - 161ms/epoch - 3ms/step\n",
            "Epoch 28/200\n",
            "47/47 - 0s - loss: 0.9297 - accuracy: 0.7447 - 166ms/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "47/47 - 0s - loss: 0.8801 - accuracy: 0.8936 - 152ms/epoch - 3ms/step\n",
            "Epoch 30/200\n",
            "47/47 - 0s - loss: 0.8419 - accuracy: 0.8298 - 172ms/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "47/47 - 0s - loss: 0.8009 - accuracy: 0.8936 - 163ms/epoch - 3ms/step\n",
            "Epoch 32/200\n",
            "47/47 - 0s - loss: 0.7709 - accuracy: 0.8085 - 186ms/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "47/47 - 0s - loss: 0.7351 - accuracy: 0.8936 - 164ms/epoch - 3ms/step\n",
            "Epoch 34/200\n",
            "47/47 - 0s - loss: 0.7220 - accuracy: 0.8936 - 162ms/epoch - 3ms/step\n",
            "Epoch 35/200\n",
            "47/47 - 0s - loss: 0.6684 - accuracy: 0.9149 - 174ms/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "47/47 - 0s - loss: 0.6367 - accuracy: 0.9149 - 163ms/epoch - 3ms/step\n",
            "Epoch 37/200\n",
            "47/47 - 0s - loss: 0.6139 - accuracy: 0.9149 - 164ms/epoch - 3ms/step\n",
            "Epoch 38/200\n",
            "47/47 - 0s - loss: 0.5911 - accuracy: 0.9149 - 158ms/epoch - 3ms/step\n",
            "Epoch 39/200\n",
            "47/47 - 0s - loss: 0.5476 - accuracy: 0.9574 - 165ms/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "47/47 - 0s - loss: 0.5230 - accuracy: 0.9362 - 153ms/epoch - 3ms/step\n",
            "Epoch 41/200\n",
            "47/47 - 0s - loss: 0.5051 - accuracy: 0.9149 - 217ms/epoch - 5ms/step\n",
            "Epoch 42/200\n",
            "47/47 - 0s - loss: 0.4709 - accuracy: 0.9787 - 262ms/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "47/47 - 0s - loss: 0.4531 - accuracy: 0.9574 - 237ms/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "47/47 - 0s - loss: 0.4421 - accuracy: 0.9787 - 205ms/epoch - 4ms/step\n",
            "Epoch 45/200\n",
            "47/47 - 0s - loss: 0.4235 - accuracy: 0.9574 - 212ms/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "47/47 - 0s - loss: 0.4108 - accuracy: 0.9787 - 222ms/epoch - 5ms/step\n",
            "Epoch 47/200\n",
            "47/47 - 0s - loss: 0.3856 - accuracy: 0.9787 - 224ms/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "47/47 - 0s - loss: 0.3676 - accuracy: 0.9787 - 226ms/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "47/47 - 0s - loss: 0.3549 - accuracy: 0.9787 - 235ms/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "47/47 - 0s - loss: 0.3405 - accuracy: 0.9574 - 223ms/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "47/47 - 0s - loss: 0.3215 - accuracy: 0.9787 - 194ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "47/47 - 0s - loss: 0.3100 - accuracy: 0.9787 - 169ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "47/47 - 0s - loss: 0.3033 - accuracy: 0.9574 - 191ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "47/47 - 0s - loss: 0.3003 - accuracy: 0.9787 - 170ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "47/47 - 0s - loss: 0.2832 - accuracy: 0.9574 - 158ms/epoch - 3ms/step\n",
            "Epoch 56/200\n",
            "47/47 - 0s - loss: 0.2732 - accuracy: 0.9787 - 150ms/epoch - 3ms/step\n",
            "Epoch 57/200\n",
            "47/47 - 0s - loss: 0.2574 - accuracy: 0.9787 - 158ms/epoch - 3ms/step\n",
            "Epoch 58/200\n",
            "47/47 - 0s - loss: 0.2502 - accuracy: 0.9787 - 159ms/epoch - 3ms/step\n",
            "Epoch 59/200\n",
            "47/47 - 0s - loss: 0.2421 - accuracy: 0.9787 - 170ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "47/47 - 0s - loss: 0.2324 - accuracy: 0.9787 - 166ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "47/47 - 0s - loss: 0.2220 - accuracy: 0.9787 - 164ms/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "47/47 - 0s - loss: 0.2159 - accuracy: 1.0000 - 176ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "47/47 - 0s - loss: 0.2076 - accuracy: 1.0000 - 155ms/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "47/47 - 0s - loss: 0.2010 - accuracy: 1.0000 - 172ms/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "47/47 - 0s - loss: 0.1974 - accuracy: 0.9787 - 166ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "47/47 - 0s - loss: 0.1892 - accuracy: 0.9787 - 167ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "47/47 - 0s - loss: 0.1807 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "47/47 - 0s - loss: 0.1729 - accuracy: 1.0000 - 154ms/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "47/47 - 0s - loss: 0.1626 - accuracy: 1.0000 - 165ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "47/47 - 0s - loss: 0.1640 - accuracy: 0.9787 - 164ms/epoch - 3ms/step\n",
            "Epoch 71/200\n",
            "47/47 - 0s - loss: 0.1591 - accuracy: 1.0000 - 165ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "47/47 - 0s - loss: 0.1543 - accuracy: 0.9787 - 167ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "47/47 - 0s - loss: 0.1510 - accuracy: 0.9787 - 175ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "47/47 - 0s - loss: 0.1480 - accuracy: 0.9787 - 162ms/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "47/47 - 0s - loss: 0.1371 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "47/47 - 0s - loss: 0.1337 - accuracy: 1.0000 - 163ms/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "47/47 - 0s - loss: 0.1280 - accuracy: 1.0000 - 167ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "47/47 - 0s - loss: 0.1288 - accuracy: 0.9787 - 172ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "47/47 - 0s - loss: 0.1326 - accuracy: 1.0000 - 161ms/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "47/47 - 0s - loss: 0.1234 - accuracy: 1.0000 - 154ms/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "47/47 - 0s - loss: 0.1153 - accuracy: 1.0000 - 179ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "47/47 - 0s - loss: 0.1108 - accuracy: 1.0000 - 179ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "47/47 - 0s - loss: 0.1063 - accuracy: 1.0000 - 176ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "47/47 - 0s - loss: 0.1012 - accuracy: 1.0000 - 182ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "47/47 - 0s - loss: 0.0964 - accuracy: 1.0000 - 159ms/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "47/47 - 0s - loss: 0.0937 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 87/200\n",
            "47/47 - 0s - loss: 0.0893 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "47/47 - 0s - loss: 0.0873 - accuracy: 1.0000 - 163ms/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "47/47 - 0s - loss: 0.0843 - accuracy: 1.0000 - 176ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "47/47 - 0s - loss: 0.0819 - accuracy: 1.0000 - 154ms/epoch - 3ms/step\n",
            "Epoch 91/200\n",
            "47/47 - 0s - loss: 0.0848 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 92/200\n",
            "47/47 - 0s - loss: 0.0816 - accuracy: 1.0000 - 163ms/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "47/47 - 0s - loss: 0.0749 - accuracy: 1.0000 - 173ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "47/47 - 0s - loss: 0.0758 - accuracy: 1.0000 - 175ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "47/47 - 0s - loss: 0.0679 - accuracy: 1.0000 - 159ms/epoch - 3ms/step\n",
            "Epoch 96/200\n",
            "47/47 - 0s - loss: 0.0667 - accuracy: 1.0000 - 172ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "47/47 - 0s - loss: 0.0639 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 98/200\n",
            "47/47 - 0s - loss: 0.0615 - accuracy: 1.0000 - 164ms/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "47/47 - 0s - loss: 0.0592 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "47/47 - 0s - loss: 0.0581 - accuracy: 1.0000 - 174ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "47/47 - 0s - loss: 0.0556 - accuracy: 1.0000 - 171ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "47/47 - 0s - loss: 0.0552 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "47/47 - 0s - loss: 0.0526 - accuracy: 1.0000 - 164ms/epoch - 3ms/step\n",
            "Epoch 104/200\n",
            "47/47 - 0s - loss: 0.0517 - accuracy: 1.0000 - 167ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "47/47 - 0s - loss: 0.0502 - accuracy: 1.0000 - 173ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "47/47 - 0s - loss: 0.0485 - accuracy: 1.0000 - 170ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "47/47 - 0s - loss: 0.0479 - accuracy: 1.0000 - 179ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "47/47 - 0s - loss: 0.0460 - accuracy: 1.0000 - 175ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "47/47 - 0s - loss: 0.0441 - accuracy: 1.0000 - 225ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "47/47 - 0s - loss: 0.0430 - accuracy: 1.0000 - 314ms/epoch - 7ms/step\n",
            "Epoch 111/200\n",
            "47/47 - 1s - loss: 0.0417 - accuracy: 1.0000 - 545ms/epoch - 12ms/step\n",
            "Epoch 112/200\n",
            "47/47 - 0s - loss: 0.0400 - accuracy: 1.0000 - 343ms/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "47/47 - 0s - loss: 0.0388 - accuracy: 1.0000 - 245ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "47/47 - 0s - loss: 0.0371 - accuracy: 1.0000 - 226ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "47/47 - 0s - loss: 0.0363 - accuracy: 1.0000 - 236ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "47/47 - 0s - loss: 0.0354 - accuracy: 1.0000 - 268ms/epoch - 6ms/step\n",
            "Epoch 117/200\n",
            "47/47 - 0s - loss: 0.0347 - accuracy: 1.0000 - 245ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "47/47 - 0s - loss: 0.0338 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 119/200\n",
            "47/47 - 0s - loss: 0.0315 - accuracy: 1.0000 - 161ms/epoch - 3ms/step\n",
            "Epoch 120/200\n",
            "47/47 - 0s - loss: 0.0304 - accuracy: 1.0000 - 164ms/epoch - 3ms/step\n",
            "Epoch 121/200\n",
            "47/47 - 0s - loss: 0.0294 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 122/200\n",
            "47/47 - 0s - loss: 0.0288 - accuracy: 1.0000 - 159ms/epoch - 3ms/step\n",
            "Epoch 123/200\n",
            "47/47 - 0s - loss: 0.0274 - accuracy: 1.0000 - 178ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "47/47 - 0s - loss: 0.0267 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 125/200\n",
            "47/47 - 0s - loss: 0.0261 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 126/200\n",
            "47/47 - 0s - loss: 0.0256 - accuracy: 1.0000 - 168ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "47/47 - 0s - loss: 0.0244 - accuracy: 1.0000 - 164ms/epoch - 3ms/step\n",
            "Epoch 128/200\n",
            "47/47 - 0s - loss: 0.0241 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n",
            "Epoch 129/200\n",
            "47/47 - 0s - loss: 0.0233 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "47/47 - 0s - loss: 0.0224 - accuracy: 1.0000 - 161ms/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "47/47 - 0s - loss: 0.0220 - accuracy: 1.0000 - 152ms/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "47/47 - 0s - loss: 0.0209 - accuracy: 1.0000 - 161ms/epoch - 3ms/step\n",
            "Epoch 133/200\n",
            "47/47 - 0s - loss: 0.0208 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 134/200\n",
            "47/47 - 0s - loss: 0.0204 - accuracy: 1.0000 - 160ms/epoch - 3ms/step\n",
            "Epoch 135/200\n",
            "47/47 - 0s - loss: 0.0195 - accuracy: 1.0000 - 186ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "47/47 - 0s - loss: 0.0189 - accuracy: 1.0000 - 146ms/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "47/47 - 0s - loss: 0.0184 - accuracy: 1.0000 - 160ms/epoch - 3ms/step\n",
            "Epoch 138/200\n",
            "47/47 - 0s - loss: 0.0179 - accuracy: 1.0000 - 160ms/epoch - 3ms/step\n",
            "Epoch 139/200\n",
            "47/47 - 0s - loss: 0.0173 - accuracy: 1.0000 - 168ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "47/47 - 0s - loss: 0.0172 - accuracy: 1.0000 - 173ms/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "47/47 - 0s - loss: 0.0166 - accuracy: 1.0000 - 174ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "47/47 - 0s - loss: 0.0159 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 143/200\n",
            "47/47 - 0s - loss: 0.0156 - accuracy: 1.0000 - 156ms/epoch - 3ms/step\n",
            "Epoch 144/200\n",
            "47/47 - 0s - loss: 0.0153 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 145/200\n",
            "47/47 - 0s - loss: 0.0146 - accuracy: 1.0000 - 161ms/epoch - 3ms/step\n",
            "Epoch 146/200\n",
            "47/47 - 0s - loss: 0.0143 - accuracy: 1.0000 - 168ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "47/47 - 0s - loss: 0.0138 - accuracy: 1.0000 - 176ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "47/47 - 0s - loss: 0.0134 - accuracy: 1.0000 - 147ms/epoch - 3ms/step\n",
            "Epoch 149/200\n",
            "47/47 - 0s - loss: 0.0132 - accuracy: 1.0000 - 150ms/epoch - 3ms/step\n",
            "Epoch 150/200\n",
            "47/47 - 0s - loss: 0.0128 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 151/200\n",
            "47/47 - 0s - loss: 0.0127 - accuracy: 1.0000 - 150ms/epoch - 3ms/step\n",
            "Epoch 152/200\n",
            "47/47 - 0s - loss: 0.0123 - accuracy: 1.0000 - 155ms/epoch - 3ms/step\n",
            "Epoch 153/200\n",
            "47/47 - 0s - loss: 0.0119 - accuracy: 1.0000 - 182ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "47/47 - 0s - loss: 0.0116 - accuracy: 1.0000 - 152ms/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "47/47 - 0s - loss: 0.0113 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 156/200\n",
            "47/47 - 0s - loss: 0.0110 - accuracy: 1.0000 - 188ms/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "47/47 - 0s - loss: 0.0106 - accuracy: 1.0000 - 159ms/epoch - 3ms/step\n",
            "Epoch 158/200\n",
            "47/47 - 0s - loss: 0.0105 - accuracy: 1.0000 - 303ms/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "47/47 - 0s - loss: 0.0102 - accuracy: 1.0000 - 275ms/epoch - 6ms/step\n",
            "Epoch 160/200\n",
            "47/47 - 0s - loss: 0.0101 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n",
            "Epoch 161/200\n",
            "47/47 - 0s - loss: 0.0097 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 162/200\n",
            "47/47 - 0s - loss: 0.0094 - accuracy: 1.0000 - 146ms/epoch - 3ms/step\n",
            "Epoch 163/200\n",
            "47/47 - 0s - loss: 0.0092 - accuracy: 1.0000 - 320ms/epoch - 7ms/step\n",
            "Epoch 164/200\n",
            "47/47 - 0s - loss: 0.0090 - accuracy: 1.0000 - 300ms/epoch - 6ms/step\n",
            "Epoch 165/200\n",
            "47/47 - 0s - loss: 0.0087 - accuracy: 1.0000 - 176ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "47/47 - 0s - loss: 0.0085 - accuracy: 1.0000 - 160ms/epoch - 3ms/step\n",
            "Epoch 167/200\n",
            "47/47 - 0s - loss: 0.0083 - accuracy: 1.0000 - 148ms/epoch - 3ms/step\n",
            "Epoch 168/200\n",
            "47/47 - 0s - loss: 0.0082 - accuracy: 1.0000 - 181ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "47/47 - 0s - loss: 0.0078 - accuracy: 1.0000 - 158ms/epoch - 3ms/step\n",
            "Epoch 170/200\n",
            "47/47 - 0s - loss: 0.0077 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n",
            "Epoch 171/200\n",
            "47/47 - 0s - loss: 0.0075 - accuracy: 1.0000 - 167ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "47/47 - 0s - loss: 0.0076 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n",
            "Epoch 173/200\n",
            "47/47 - 0s - loss: 0.0072 - accuracy: 1.0000 - 185ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "47/47 - 0s - loss: 0.0070 - accuracy: 1.0000 - 245ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "47/47 - 0s - loss: 0.0068 - accuracy: 1.0000 - 234ms/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "47/47 - 0s - loss: 0.0066 - accuracy: 1.0000 - 209ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "47/47 - 0s - loss: 0.0064 - accuracy: 1.0000 - 218ms/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "47/47 - 0s - loss: 0.0063 - accuracy: 1.0000 - 223ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "47/47 - 0s - loss: 0.0062 - accuracy: 1.0000 - 227ms/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "47/47 - 0s - loss: 0.0060 - accuracy: 1.0000 - 244ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "47/47 - 0s - loss: 0.0059 - accuracy: 1.0000 - 243ms/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "47/47 - 0s - loss: 0.0057 - accuracy: 1.0000 - 254ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "47/47 - 0s - loss: 0.0056 - accuracy: 1.0000 - 228ms/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "47/47 - 0s - loss: 0.0055 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 185/200\n",
            "47/47 - 0s - loss: 0.0054 - accuracy: 1.0000 - 168ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "47/47 - 0s - loss: 0.0052 - accuracy: 1.0000 - 165ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "47/47 - 0s - loss: 0.0050 - accuracy: 1.0000 - 165ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "47/47 - 0s - loss: 0.0050 - accuracy: 1.0000 - 168ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "47/47 - 0s - loss: 0.0048 - accuracy: 1.0000 - 157ms/epoch - 3ms/step\n",
            "Epoch 190/200\n",
            "47/47 - 0s - loss: 0.0048 - accuracy: 1.0000 - 159ms/epoch - 3ms/step\n",
            "Epoch 191/200\n",
            "47/47 - 0s - loss: 0.0046 - accuracy: 1.0000 - 164ms/epoch - 3ms/step\n",
            "Epoch 192/200\n",
            "47/47 - 0s - loss: 0.0045 - accuracy: 1.0000 - 166ms/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "47/47 - 0s - loss: 0.0044 - accuracy: 1.0000 - 155ms/epoch - 3ms/step\n",
            "Epoch 194/200\n",
            "47/47 - 0s - loss: 0.0043 - accuracy: 1.0000 - 163ms/epoch - 3ms/step\n",
            "Epoch 195/200\n",
            "47/47 - 0s - loss: 0.0042 - accuracy: 1.0000 - 160ms/epoch - 3ms/step\n",
            "Epoch 196/200\n",
            "47/47 - 0s - loss: 0.0041 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n",
            "Epoch 197/200\n",
            "47/47 - 0s - loss: 0.0040 - accuracy: 1.0000 - 182ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "47/47 - 0s - loss: 0.0039 - accuracy: 1.0000 - 165ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "47/47 - 0s - loss: 0.0038 - accuracy: 1.0000 - 167ms/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "47/47 - 0s - loss: 0.0037 - accuracy: 1.0000 - 162ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ddc096730>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed='오늘 우리'\n",
        "#시드 문자열 길이를 seq_length와 동일하게 설정\n",
        "\n",
        "generated_text = seed"
      ],
      "metadata": {
        "id": "CwZVV91YKO74"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = np.array([char_to_idx[char] for char in seed])\n",
        "\n",
        "input_seq\n",
        "#seed의 문자를 정수 인덱스로 변경"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzkb5yMFP8cP",
        "outputId": "80425ee7-481d-4d3f-bbb2-a95ea6982542"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23,  8,  0, 25, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = input_seq.reshape(1, seq_length)\n",
        "input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyMq4uEZQKgn",
        "outputId": "7ab96d1b-341b-4a4a-ef5b-bde01090edbd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23,  8,  0, 25, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(50):\n",
        "    predicted_idx = np.argmax(model.predict(input_seq))\n",
        "    #입력된 sequence(문장)을 31개를 다중분류하기 위해 가장 높게 나온 확률을 predicted_idx에 넣음\n",
        "    predicted_char = idx_to_char[predicted_idx]\n",
        "    generated_text += predicted_char\n",
        "\n",
        "    print('input_seq', input_seq)\n",
        "    print('predicted_idx', predicted_idx)\n",
        "\n",
        "    predicted_idx = np.array(predicted_idx).reshape(1,1)\n",
        "    input_seq = np.concatenate((input_seq[:, 1:], predicted_idx), axis=1)\n",
        "    # input_seq[:, 1:] 맨 앞에 있는 거 빼고 다음 문자 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7ST3GmXQfmP",
        "outputId": "3b7548dd-bb8e-40e0-ff49-ed0cb23ca283"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[23  8  0 25 13]]\n",
            "predicted_idx 7\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input_seq [[ 8  0 25 13  7]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[ 0 25 13  7  0]]\n",
            "predicted_idx 20\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[25 13  7  0 20]]\n",
            "predicted_idx 19\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[13  7  0 20 19]]\n",
            "predicted_idx 15\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[ 7  0 20 19 15]]\n",
            "predicted_idx 11\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input_seq [[ 0 20 19 15 11]]\n",
            "predicted_idx 26\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[20 19 15 11 26]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[19 15 11 26  0]]\n",
            "predicted_idx 3\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[15 11 26  0  3]]\n",
            "predicted_idx 16\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[11 26  0  3 16]]\n",
            "predicted_idx 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "input_seq [[26  0  3 16 30]]\n",
            "predicted_idx 19\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 0  3 16 30 19]]\n",
            "predicted_idx 24\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 3 16 30 19 24]]\n",
            "predicted_idx 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[16 30 19 24  1]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[30 19 24  1  0]]\n",
            "predicted_idx 17\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[19 24  1  0 17]]\n",
            "predicted_idx 21\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "input_seq [[24  1  0 17 21]]\n",
            "predicted_idx 28\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[ 1  0 17 21 28]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "input_seq [[ 0 17 21 28  0]]\n",
            "predicted_idx 4\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "input_seq [[17 21 28  0  4]]\n",
            "predicted_idx 6\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[21 28  0  4  6]]\n",
            "predicted_idx 18\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[28  0  4  6 18]]\n",
            "predicted_idx 9\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 0  4  6 18  9]]\n",
            "predicted_idx 10\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 4  6 18  9 10]]\n",
            "predicted_idx 1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[ 6 18  9 10  1]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[18  9 10  1  0]]\n",
            "predicted_idx 5\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 9 10  1  0  5]]\n",
            "predicted_idx 7\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[10  1  0  5  7]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[1 0 5 7 0]]\n",
            "predicted_idx 29\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "input_seq [[ 0  5  7  0 29]]\n",
            "predicted_idx 22\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[ 5  7  0 29 22]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "input_seq [[ 7  0 29 22  0]]\n",
            "predicted_idx 2\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input_seq [[ 0 29 22  0  2]]\n",
            "predicted_idx 9\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[29 22  0  2  9]]\n",
            "predicted_idx 10\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[22  0  2  9 10]]\n",
            "predicted_idx 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 0  2  9 10  1]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "input_seq [[ 2  9 10  1  0]]\n",
            "predicted_idx 10\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "input_seq [[ 9 10  1  0 10]]\n",
            "predicted_idx 27\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[10  1  0 10 27]]\n",
            "predicted_idx 22\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[ 1  0 10 27 22]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[ 0 10 27 22  0]]\n",
            "predicted_idx 12\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input_seq [[10 27 22  0 12]]\n",
            "predicted_idx 0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "input_seq [[27 22  0 12  0]]\n",
            "predicted_idx 14\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[22  0 12  0 14]]\n",
            "predicted_idx 5\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 0 12  0 14  5]]\n",
            "predicted_idx 24\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[12  0 14  5 24]]\n",
            "predicted_idx 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[ 0 14  5 24  1]]\n",
            "predicted_idx 3\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "input_seq [[14  5 24  1  3]]\n",
            "predicted_idx 16\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "input_seq [[ 5 24  1  3 16]]\n",
            "predicted_idx 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c8jwNkRTQxr3",
        "outputId": "dc207871-9449-4f62-d040-7a3fa5048094"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘 우리는 언어모델을 공부했어요. 수업이 끝났습니다. 나는 집에 갑니다. 다음에 또 만나요.공부했'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HWYCSvuMTMtn"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#torch.nn 문서 읽기\n",
        "``` python\n",
        "설명에 그래프를 만들기 위한 \"basic building block\"이라고 쓰여져 있습니다!\n",
        "\n",
        "저희가 다양한 함수들을 잘 활용하면\n",
        "여기서 말하는 \"basic building block\"을 만들 수 있겠지만 시간이 걸리니까\n",
        "PyTorch에서 미리 만들어두고 이를 \"torch.nn\"으로 묶어 쉽게 사용하게 만들었어요! \n",
        "\n",
        "여기서 제공해주는 블럭들을 잘 이용하면 그래프라는 딥러닝 모델을 만들 수 있을 것 같아요!\n",
        "\n",
        "매우 중요해보이지만 내용이 정말 많네요!\n",
        "이 많은 내용을 다 볼 수는 없으니까 간단하게 훑어보겠습니다!\n",
        "```\n",
        "\n",
        "- [torch.nn 문서 - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html)"
      ],
      "metadata": {
        "id": "x9ornn1kBsfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn `Linear Layers`\n",
        "\n",
        "``` python\n",
        "가볍게 읽기만 하려고 했는데 그래도 한 두개는 직접 예제를 따라치면 좋을 것 같아요!\n",
        "딥러닝을 공부하면, y = WX + b 라는 공식을 자주 볼거예요!\n",
        "이 linear transformation을 구현해놓은 \"nn.Linear\"가 속해잇는\n",
        "\"Linear Layers\" 항목을 잠깐만 같이 살펴보겠습니다!\n",
        "```\n",
        "\n",
        "- [torch.nn Linear Layers - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html#linear-layers)"
      ],
      "metadata": {
        "id": "daSv9oMiEsca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Linear\n",
        "\n",
        "\n",
        "``` python\n",
        "pytorch로 딥러닝 설계를 한다면, 이 \"nn.Linear\"는 정말 많이 보게 될거예요!\n",
        "```\n",
        "\n",
        "- [torch.nn.Linear - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "\n",
        "**힌트**\n",
        "- PyTorch에는 tensor 크기(or 모양)를 반환하는 함수가 있어요! 영어로 크기가 무엇일까요?"
      ],
      "metadata": {
        "id": "jzLfuiETE-gW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSJiqVMjPDkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Xg4tHUBRFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbcecc8-7f5d-4aef-b5c5-e7a678303626"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# nn.Linear의 사용방법을 예시로 듬\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# TODO : tensor X의 크기는 (2, 2)입니다\n",
        "#        nn.Linear를 사용하여서 (2, 5)로 크기를 바꾸고 이 크기를 출력하세요!\n",
        "\n",
        "linear = nn.Linear(2,5)\n",
        "output = linear(X)\n",
        "output.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcxc8j6yRSbp",
        "outputId": "462cd4e3-a8ce-4ebb-9557-2a0d18f93afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Identity\n",
        "이 layer도 유용하게 사용됩니다. 다만 딥러닝을 막 배우는 단계에서 이 layer를 사용할 일은 거의 없기 때문에 사용처를 아실 필요는 없습니다. 다만 궁금해하실 분들을 위해 링크를 남겨놓습니다.\n",
        "\n",
        "``` python\n",
        "\"nn.Identity\"는 입력과 출력이 동일하게 나오는데 도대체 왜 만들어놓은 걸까요?\n",
        "그래도.. 한번 사용해봐요!\n",
        "```\n",
        "\n",
        "- [torch.nn.Identity - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity)\n",
        "\n",
        "**유용한 자료**\n",
        "- [What is the use of nn.Identity? - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-use-of-nn-identity/51781)\n",
        "- [What is the idea behind using nn.Identity for residual learning? - Stack Overflow](https://stackoverflow.com/questions/64229717/what-is-the-idea-behind-using-nn-identity-for-residual-learning)"
      ],
      "metadata": {
        "id": "6pfGOu3CGJJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "X = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "# TODO : nn.Identity를 생성해 X를 입력시킨 후 나온 출력값이 X와 동일한지 확인해보세요!\n",
        "identity = nn.Identity()\n",
        "output = identity(X)\n",
        "output"
      ],
      "metadata": {
        "id": "NGlUb2HbGXeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1c8a2f-e57d-4477-d312-93cda544f134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom 모델 제작을 위한 nn.Module 클래스\n",
        "\n",
        "```\n",
        "PyTorch 라이브러리가 제공해주는 다양한 기능들과 nn.Module를 활용하여 모델 제작 및 분석을 진행해볼 것입니다!\n",
        "```\n",
        "\n",
        "PyTorch가 제공해주는 기능들을 조합하여서 모델을 만들 차례입니다. 모델을 만들기 위해서 기능들을 단순히 나열해놓기만 한다면 지저분하겠죠? 그래서 PyTorch는 이런 일련의 기능들을 한 곳에 모아 하나의 모델로 추상화할 수 있게끔 클래스를 제공합니다.\n",
        "\n",
        "```\n",
        "nn.Module\n",
        "```\n",
        "- [torch.nn.Module - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "\n",
        "`nn.Module` 클래스는 여러 기능들을 한 곳에 모아놓는 상자 역할을 합니다.<br>\n",
        "`nn.Module`이라는 상자는 다른 `nn.Module` 상자를 포함할 수도 있습니다!<br>\n",
        "어떻게 사용햐느냐에 따라 `nn.Module` 상자는 다른 의미를 가집니다.\n",
        "\n",
        "- `nn.Module`이라는 상자에 `기능`들을 가득 모아놓은 경우 `basic building block`\n",
        "- `nn.Module`이라는 상자에 `basic building block`인 `nn.Module`들을 가득 모아놓은 경우 `딥러닝 모델`\n",
        "- `nn.Module`이라는 상자에 `딥러닝 모델`인 `nn.Module`들을 가득 모아놓은 경우 `더욱 큰 딥러닝 모델`\n",
        "\n",
        "`nn.Module`은 빈 상자일 뿐 이를 어떻게 사용할지는 온전히 설계자의 몫입니다!<br>\n",
        "`기능`과 `basic building block`과 `딥러닝 모델`을 혼재해서 마구잡이로 담을 수도 있고<br>\n",
        "`기능`은 `기능`끼리 `block`은 `block`끼리 계층적으로 담을 수도 있습니다!\n",
        "\n",
        "우리는 여기서 `nn.Module`를 이용해 모델을 제작해보고 제작한 모델이 어떻게 구성되어있는지 분석해볼 것입니다!<br>\n",
        "추가적으로 custom 모델 제작에 유용할 수 있는 `nn.Module`의 기능들도 살펴볼 것입니다!\n",
        "\n",
        "- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)"
      ],
      "metadata": {
        "id": "6fF_tccTGy6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Documentation에서 nn.Module을 검색해서 찾으세요!\n",
        "- nn.Module 문서의 설명을 읽어보세요!\n",
        "    - ![](https://github.com/IllgamhoDuck/PyTorch/blob/main/document_image/nn.Module.png?raw=true)\n",
        "- nn.Module 내부의 method들의 이름과 설명을 가볍게 훑어보세요!"
      ],
      "metadata": {
        "id": "0ZmopkDNHgHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Module 모델 제작"
      ],
      "metadata": {
        "id": "mHlNQAiURWKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"nn.Module\"를 이용해서 더하기 연산을 하는 모델을 만들어봅시다!"
      ],
      "metadata": {
        "id": "CGtgXHBFH77c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : Add 모델을 완성하세요!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self):\n",
        "        # TODO : init 과정에서 반드시 들어가야 하는 super 관련 코드가 있습니다\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # TODO : torch.add 함수를 사용해서 더하기 연산을 해주세요!\n",
        "        output = torch.add(x1, x2)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x1 = torch.tensor([1])\n",
        "x2 = torch.tensor([2])\n",
        "\n",
        "add = Add()\n",
        "output = add(x1, x2)\n",
        "\n",
        "output #3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuAQ3RqDG8vg",
        "outputId": "98bd3908-89f2-4a3e-cdfd-06f961221391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` python\n",
        "super를 통해서 init을 하는 것은 왜 그런걸까요?\n",
        "\n",
        "아래 링크의 글을 읽으니까 의문이 좀 풀리는 것 같아요! \n",
        "```\n",
        "\n",
        "**유용한 자료**\n",
        "- [Why is the super constructor necessary in PyTorch custom modules? - Stack Overflow](https://stackoverflow.com/questions/63058355/why-is-the-super-constructor-necessary-in-pytorch-custom-modules)"
      ],
      "metadata": {
        "id": "l1IXdUATIN4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Container\n",
        "\n",
        "``` python\n",
        "저희가 원하는 모듈(Module)을 만들었습니다!\n",
        "\n",
        "이렇게 만든 모듈(Module)들을 묶어서 사용하고 싶은데 어떻게 하는걸까요?\n",
        "파이썬의 리스트에 모듈들을 보관하면 되는걸까요?\n",
        "\n",
        "Documentation을 열심히 찾아보니까 관련된 함수들이\n",
        "\"torch.nn\"의 Container 항목에 포함되어있네요!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n",
        "- [Containers  - PyTorch 공식 문서](https://pytorch.org/docs/stable/nn.html#containers)"
      ],
      "metadata": {
        "id": "181G00SiIg6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### torch.nn.Sequential\n",
        "\n",
        "``` python\n",
        "모듈(Module)들을 하나로 묶어 순차적으로 실행시키고 싶을때 torch.nn.Sequential를 사용한다고 합니다!\n",
        "```\n",
        "\n",
        "- [torch.nn.Sequential - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)"
      ],
      "metadata": {
        "id": "V7p23EsLIq1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : 다음의 모듈(Module)을 읽고 이해해보세요!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "# TODO : 위에 모듈(Module)과 nn.Sequential를 이용해서\n",
        "#        입력값 x가 주어지면 다음의 연산을 처리하는 모델을 만들어보세요!\n",
        "#        y = x + 3 + 2 + 5\n",
        "calculator = nn.Sequential(Add(3),\n",
        "                           Add(2),\n",
        "                           Add(5))\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "output = calculator(x)\n",
        "\n",
        "output # 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Vz0pLnIE6n",
        "outputId": "d807fd03-f6dc-4520-9b99-1fa1e32a210b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### torch.nn.ModuleList\n",
        "\n",
        "``` python\n",
        "torch.nn.Sequential은 묶어놓은 모듈들을 차례대로 수행하기 때문에 실행 순서가 정해져있는 기능들을 하나로 묶어두기 좋아보입니다!\n",
        "\n",
        "하지만 파이썬의 list처럼 모아두기만 하고 그때그때 원하는 것만\n",
        "인덱싱(indexing)을 통해 쓰고 싶으면 torch.nn.ModuleList을 쓰면 되지 않을까요?\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleList - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)"
      ],
      "metadata": {
        "id": "fYzmmk7RKpL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : 다음의 모듈(Module)을 읽고 이해해보세요!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator 모델을 완성하세요!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : self.add_list에 담긴 모듈들을 이용하여서\n",
        "        #        y = ((x + 3) + 2) + 5 의 연산을 구현하세요!\n",
        "\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "\n",
        "output # 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWMLPX2pIwY-",
        "outputId": "ea0bc2cb-5b8f-4454-e0c3-860ebc9d9d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  torch.nn.ModuleDict\n",
        "\n",
        "``` python\n",
        "torch.nn.ModuleLists 정말 편리하네요!!\n",
        "하지만 만약 리스트에 담긴 모듈의 크기가 정말 커진다면 나중에는 인덱싱(indexing)으로 원하는 모듈을 찾기가 정말 힘들어질 것 같아요!\n",
        "\n",
        "파이썬의 dict처럼 특정 모듈을 key값을 이용해 보관해놓는다면 나중에 원하는 모듈을 가져올때 훨씬 수월하지 않을까요?\n",
        "마침 PyTorch에 torch.nn.ModuleDict이 있네요! 같이 써봐요!\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleDict - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict)"
      ],
      "metadata": {
        "id": "a-n5eTPPKxZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : 다음의 모듈(Module)을 읽고 이해해보세요!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator 모델을 완성하세요!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.add_dict = nn.ModuleDict({'add2': Add(2),\n",
        "                                       'add3': Add(3),\n",
        "                                       'add5': Add(5)})\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : self.add_dict에 담긴 모듈들을 이용하여서\n",
        "        #        y = ((x + 3) + 2) + 5 의 연산을 구현하세요!\n",
        "\n",
        "        x = self.add_dict['add3'](x)\n",
        "        x = self.add_dict['add2'](x)\n",
        "        x = self.add_dict['add5'](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "calculator = Calculator()\n",
        "output = calculator(x)\n",
        "\n",
        "output # 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvLi8HHVKv_e",
        "outputId": "a588e8d5-43e0-47bf-ebcf-6a926b30b10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='red'><b>[ 퀴즈 ]</b></font> Python List vs PyTorch ModuleList\n",
        "``` python\n",
        "그런데 가만히 생각해보니까 파이썬에도 List가 있는데 왜 굳이 PyTorch에서는 ModuleList를 별도로 만들어두었을까요?\n",
        "\n",
        "그 이유가 궁금해요!\n",
        "```\n",
        "\n",
        "- [torch.nn.ModuleList - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList)\n",
        "\n",
        "**힌트**\n",
        "- 아래에 작성된 코드를 실행시키시면 힌트를 얻을 수 있습니다!"
      ],
      "metadata": {
        "id": "Gh2d5DjjK_2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "\n",
        "class PythonList(nn.Module):\n",
        "    \"\"\"Python List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Python List\n",
        "        self.add_list = [Add(2), Add(3), Add(5)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class PyTorchList(nn.Module):\n",
        "    \"\"\"PyTorch List\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Pytorch ModuleList\n",
        "        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.add_list[1](x)\n",
        "        x = self.add_list[0](x)\n",
        "        x = self.add_list[2](x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "RWuptUP-K544"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.tensor([1])\n",
        "\n",
        "python_list = PythonList()\n",
        "pytorch_list = PyTorchList()\n",
        "\n",
        "# 기능 동작은 동일합니다!\n",
        "print(python_list(x), pytorch_list(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9e7CpKMLHON",
        "outputId": "eb32bdd2-8aca-4ee9-a021-07be3948105c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11]) tensor([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python List로 모아놓은 모듈들이 감쪽같이 사라졌습니다!\n",
        "python_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijEW2bs9LIOq",
        "outputId": "a7def0c5-0f07-40b6-b27c-05743ed2477b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonList()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하지만 PyTorch의 ModuleList로 모아놓은 모듈들은 짠! 하고 나타나네요!\n",
        "pytorch_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWOZMZG2LJO6",
        "outputId": "68aa5ef3-1831-47c7-847d-4943c7376f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PyTorchList(\n",
              "  (add_list): ModuleList(\n",
              "    (0): Add()\n",
              "    (1): Add()\n",
              "    (2): Add()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# TODO : 맞고 틀리고가 없는 문제입니다. 문서를 읽고 답을 자유로이 적어주세요\n",
        "\n",
        "기능적으로는 완전히 동일하다.\n",
        "\n",
        "기능적으로는 완전히 동일하다.\n",
        "\n",
        "- Python list\n",
        "    - list에 담아 놓은 모듈 전체가 nn.Module의 submodule로 등록이 안된다.\n",
        "\n",
        "- Pytorch ModuleList\n",
        "    - ModuleList 내부에 담긴 Module들이 nn.Module의 submodule로 등록이 된다!\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tkR4bqOdNd1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 조건문\n",
        "\n",
        "``` python\n",
        "모델을 만들때 PyTorch는 동적 계산 그래프를 사용하기 때문에\n",
        "if / else 와 같은 조건문을 쉽게 사용할 수 있는 장점이 있습니다!\n",
        "\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n",
        "\n",
        "**유용한 자료**\n",
        "- [Can someone explain the use of a dynamic graph? - Reddit](https://www.reddit.com/r/pytorch/comments/8kpsjy/can_someone_explain_the_use_of_a_dynamic_graph/)"
      ],
      "metadata": {
        "id": "XVi3t4EZN0R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# TODO : 다음의 모듈(Module)을 읽고 이해해보세요!\n",
        "class Add(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.value\n",
        "\n",
        "class Sub(nn.Module):\n",
        "    def __init__(self, value):\n",
        "        super().__init__()\n",
        "        self.value = value\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.value\n",
        "\n",
        "\n",
        "# TODO : Calculator 모델을 완성하세요!\n",
        "class Calculator(nn.Module):\n",
        "    def __init__(self, cal_type):\n",
        "        super().__init__()\n",
        "        self.cal_type = cal_type\n",
        "        self.add = Add(3)\n",
        "        self.sub = Sub(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : cal_type에 \"add\"가 입력되면 더하기 모델 y = x + 3\n",
        "        #                   \"sub\"가 입력되면 빼기 모델 y = x - 3\n",
        "        #                   \"add\", \"sub\"가 아닌 다른 문자열이 입력되면 ValueError을 일으키세요!\n",
        "        #        if/elif/else 조건문을 사용하세요! \n",
        "        if self.cal_type == \"add\":\n",
        "            x = self.add(x)\n",
        "        elif self.cal_type == \"sub\":\n",
        "            x = self.sub(x)\n",
        "        else:\n",
        "            raise ValueError(f'cal_type should be add or sub. entered {self.cal_type}')\n",
        "        \n",
        "\n",
        "        return x\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.tensor([5])\n",
        "\n",
        "try:\n",
        "    calculator = Calculator(\"none\")\n",
        "    output = calculator(x)\n",
        "\n",
        "    print(\"잘못된 문자열 입력에는 에러를 발생시키세요!!\")\n",
        "except ValueError:\n",
        "    calculator = Calculator(\"add\")\n",
        "    add_output = calculator(x)\n",
        "\n",
        "    calculator = Calculator(\"sub\")\n",
        "    sub_output = calculator(x)\n",
        "    \n",
        "    if add_output == 8 and sub_output == 2:\n",
        "        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\")\n",
        "    else:\n",
        "        print(\"다시 도전해봐요!\")\n",
        "except:\n",
        "    print(\"ValueError를 발생시키세요!!\")\n"
      ],
      "metadata": {
        "id": "V6Vepz3iLKLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d18c9d-d972-412f-f04a-21ca189efd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter\n",
        "\n",
        "``` python\n",
        "linear transformation인 Y = XW + b 에 대해서 생각하고 있었어요!\n",
        "X는 저희가 torch.Tensor로 만들어서 제공하는데 W, b는 어디서 만들죠?\n",
        "\n",
        "언뜻 친구한테 들었는데 nn.Module안에 미리 만들어진 tensor들을\n",
        "보관할 수 있다고 들은 것 같아요! 뭐랬지, 아마 Parameter라고 한 것 같아요!\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n",
        "- [torch.nn.parameter.Parameter - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter)\n",
        "\n",
        "**힌트**\n",
        "- [PyTorch linear.py L81 - L85 - PyTorch 공식 Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L81-L85)"
      ],
      "metadata": {
        "id": "28imVTVYOOoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# TODO : Linear 모델을 완성하세요!\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO : W, b parameter를 생성하세요! 모두 1로 초기화해주세요!\n",
        "        self.W = Parameter(torch.ones(out_features, in_features))\n",
        "        self.b = Parameter(torch.ones(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "x = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "linear = Linear(2, 3)\n",
        "output = linear(x)\n",
        "\n",
        "\n",
        "output \n",
        "#output == torch.Tensor([[4, 4, 4],\n",
        "                     # [8, 8, 8]])):"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvRqLdCEOS3e",
        "outputId": "aed56901-f4d3-41e2-be01-943afc239dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 4., 4.],\n",
              "        [8., 8., 8.]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor vs Parameter\n",
        "``` python\n",
        "생각해보면 W, b도 tensor를 이용하면 되는 것 아닌가요?\n",
        "왜 굳이 Parameter라는 별개의 클래스를 사용하는 거죠?\n",
        "```\n",
        "**힌트**\n",
        "- 아래에 작성된 코드를 실행시키시면 힌트를 얻을 수 있습니다!"
      ],
      "metadata": {
        "id": "miKoOICOOsy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class Linear_Parameter(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # torch.nn.parameter.Parameter\n",
        "        self.W = Parameter(torch.ones((out_features, in_features)))\n",
        "        self.b = Parameter(torch.ones(out_features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Linear_Tensor(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # torch.Tensor\n",
        "        self.W = torch.ones((out_features, in_features))\n",
        "        self.b = torch.ones(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = torch.addmm(self.b, x, self.W.T)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "x = torch.Tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "linear_parameter = Linear_Parameter(2, 3)\n",
        "linear_tensor = Linear_Tensor(2, 3)\n",
        "\n",
        "output_parameter = linear_parameter(x)\n",
        "output_tensor = linear_tensor(x)\n",
        "\n",
        "# 값은 동일하게 계산되는 것을 볼 수 있습니다!\n",
        "# 하지만 출력을 자세히 보시면, Parameter를 이용해서 W, b를 만들 경우에만\n",
        "# output tensor에 gradient를 계산하는 함수인 grad_fn가 생성됩니다\n",
        "print(output_parameter)\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egvE-TfUOlfx",
        "outputId": "bd07a53e-8dea-4396-8bfa-fa5189ee863d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4., 4., 4.],\n",
            "        [8., 8., 8.]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[4., 4., 4.],\n",
            "        [8., 8., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter로 만든 W, b는 저장할 tensor로 지정되어있습니다\n",
        "linear_parameter.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIxOC5acOykT",
        "outputId": "9cdab7ca-3ea8-4a8e-d5c4-264d24c89d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('W', tensor([[1., 1.],\n",
              "                      [1., 1.],\n",
              "                      [1., 1.]])), ('b', tensor([1., 1., 1.]))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.Tensor로 만든 W, b는 저장되지 않습니다\n",
        "linear_tensor.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqaoxlxlOz4f",
        "outputId": "67606b59-ba3b-4937-b5c6-c28002ebeec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# TODO : 맞고 틀리고가 없는 문제입니다. 문서를 읽고 답을 자유로이 적어주세요\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "nC-6jsT7O19r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Buffer\n",
        "\n",
        "``` python\n",
        "Custom 모델을 만들때 대부분 torch.nn에 구현된 layer들을 가져가다 사용하기 때문에 Parameter를 직접 다뤄볼 일은 매우 드물어요!\n",
        "\n",
        "저희가 직접 새로운 layer를 작성할게 아니라면 Parameter를 사용할 일이 거의 없습니다!\n",
        "\n",
        "하지만 Parameter를 사용할줄 아는 것은 중요하다면서 칭찬해줬어요!\n",
        "추가적으로 buffer라는 것도 있다면서 가르켜주었죠!\n",
        "\n",
        "일반적인 Tensor는 Parameter와 다르게 gradient를 계산하지 않아\n",
        "값도 업데이트 되지 않고, 모델을 저장할 때 무시되잖아요?\n",
        "\n",
        "하지만 Parameter로 지정하지 않아서 값이 업데이트 되지 않는다 해도\n",
        "저장하고싶은 tensor가 있을 수도 있잖아요?\n",
        "\n",
        "그럴때는 buffer에 tensor를 등록해주면 되요!\n",
        "모델을 저장할때 Parameter뿐만 아니라 buffer로 등록된 tensor들도 같이 저장되요!\n",
        "\n",
        "정리하면 다음과 같아요!\n",
        "\n",
        "- \"Tensor\"\n",
        "    - ❌ gradient 계산\n",
        "    - ❌ 값 업데이트\n",
        "    - ❌ 모델 저장시 값 저장\n",
        "- \"Parameter\"\n",
        "    - ✅ gradient 계산\n",
        "    - ✅ 값 업데이트\n",
        "    - ✅ 모델 저장시 값 저장\n",
        "- \"Buffer\"\n",
        "    - ❌ gradient 계산\n",
        "    - ❌ 값 업데이트\n",
        "    - ✅ 모델 저장시 값 저장\n",
        "```\n",
        "\n",
        "- [Documentation main - PyTorch 공식 문서](https://pytorch.org/docs/stable/index.html)\n",
        "- [register_buffer - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=register_buffer#torch.nn.Module.register_buffer)\n",
        "\n",
        "**유용한 자료**\n",
        "- [What is the difference between `register_buffer` and `register_parameter` of `nn.Module` - PyTorch Forum](https://discuss.pytorch.org/t/what-is-the-difference-between-register-buffer-and-register-parameter-of-nn-module/32723)"
      ],
      "metadata": {
        "id": "rj0LvMpbPWb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "# TODO : Model 모델을 완성하세요!\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.parameter = Parameter(torch.Tensor([7]))\n",
        "        self.tensor = torch.Tensor([7])\n",
        "\n",
        "        # TODO : torch.Tensor([7])를 buffer이라는 이름으로 buffer에 등록해보세요!\n",
        "        self.register_buffer(None, None, persistent=True)\n",
        "\n",
        "\n",
        "\n",
        "# 아래 코드는 수정하실 필요가 없습니다!\n",
        "model = Model()\n",
        "\n",
        "try:\n",
        "    buffer = model.get_buffer('buffer')\n",
        "    if buffer == 7:\n",
        "        print(\"🎉🎉🎉 성공!!! 🎉🎉🎉\\n\")\n",
        "        print(\"🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\")\n",
        "        print(model.state_dict())\n",
        "    else:\n",
        "        print(\"다시 도전해봐요!\")\n",
        "except:\n",
        "    print(\"다시 도전해봐요!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc_GFvzhO0rq",
        "outputId": "3c754e24-4a72-4014-81af-40bede4f564b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉🎉🎉 성공!!! 🎉🎉🎉\n",
            "\n",
            "🎉 이제 buffer에 등록된 tensor는 모델이 저장될 때 같이 저장될거예요! 🎉\n",
            "OrderedDict([('parameter', tensor([7.])), ('buffer', tensor([7.]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` python\n",
        "아 너무 어려워요... 그래서 이걸 어디다 쓰는데요..?\n",
        "```\n",
        "``` python\n",
        "한가지 좋은 예시로 BatchNorm에서 사용되요!\n",
        "아래 링크를 첨부해놓았으니 더 알고 싶으면 읽어보세요!\n",
        "\n",
        "이 buffer도 Parameter와 마찬가지로 사용할 일은 드물 것 같아요!\n",
        "하지만 알아두면 언젠가 요긴하게 쓸 날이 오겠죠?\n",
        "```\n",
        "\n",
        "\n",
        "**유용한 자료**\n",
        "- [torch.nn.BatchNorm1d - PyTorch 공식 문서](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html?highlight=buffer)\n",
        "- [PyTorch batchnorm.py L51 - L52 - PyTorch 공식 Github](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L51-L52)"
      ],
      "metadata": {
        "id": "lTdZS-joPyiN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlCg-tVvdOgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
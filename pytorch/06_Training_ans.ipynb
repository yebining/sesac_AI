{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y8AwKGB8-Mo"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S-IHD88-My"
      },
      "source": [
        "# Training a Neural Network\n",
        "\n",
        "## Softmax 층\n",
        "\n",
        "$$y_i = \\text{Softmax}(z_i) = \\dfrac{\\exp(z_i)}{\\sum_j^k \\exp(z_j)}$$\n",
        "\n",
        "`torch.softmax` 를 사용하면 함수처럼 사용할 수 있고, `nn.Softmax()`를 사용해서 객체 생성 후 하나의 층 처럼 사용할 수도 있다. 다만 Softmax 할 차원을 지정해줘야한다.\n",
        "\n",
        "* PyTorch Docs: [softmax](https://pytorch.org/docs/stable/nn.html#softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVQIuRac8-Mz",
        "outputId": "656afdf9-ea2e-449f-bb74-6d9136008a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.FloatTensor([3, 1, 5, 9])\n",
        "prob = torch.softmax(x, dim=0)\n",
        "print(f\"{prob.numpy().round(3)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.002 0.    0.018 0.979]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBNosEXf8-M4",
        "outputId": "c0579dba-b2bc-474d-9e63-69efba103c7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "softmax_layer = nn.Softmax(dim=1)\n",
        "x = torch.FloatTensor([[3, 1, 5, 9], \n",
        "                       [4, 6, 5, 3]])\n",
        "print(x.size())\n",
        "prob = softmax_layer(x)\n",
        "print(f\"{prob.numpy().round(3)}\\n\")\n",
        "print(f\"dim=1 으로 합을 하면 1이 된다: {prob.sum(1)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "[[0.002 0.    0.018 0.979]\n",
            " [0.087 0.644 0.237 0.032]]\n",
            "\n",
            "dim=1 으로 합을 하면 1이 된다: tensor([1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yOAcOq8-M8"
      },
      "source": [
        "보통 softmax의 0에 가까운 아주 작은 수라서 log를 취해서 `torch.log_softmax`를 사용한다(혹은 `nn.LogSoftmax`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77lk2P_A8-M-",
        "outputId": "afcbb982-951e-4c6b-8afd-5b663091edf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.0209, -8.0209, -4.0209, -0.0209],\n",
              "        [-2.4402, -0.4402, -1.4402, -3.4402]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWG4Ba_w8-NA"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "XOR 문제는 0과 1 두 가지 클래스를 분류하는 문제다. Cross-Entropy 를 사용할 수 있다. \n",
        "\n",
        "따라서 네트워크의 마지막 층을 2개로 출력하고 `Softmax` 층을 넣어야 한다. 다만 PyTorch의 Cross Entropy Loss(`nn.CrossEntropyLoss`)에는 `LogSoftmax`가 포함되어 있어서 넣지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH9rDNAO8-NB"
      },
      "source": [
        "torch.manual_seed(70)\n",
        "\n",
        "class XOR(nn.Module):\n",
        "    \"\"\"XOR Network\"\"\"\n",
        "    def __init__(self):\n",
        "        super(XOR, self).__init__()\n",
        "        # 층을 구성\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2,4),  # in_features, out_features\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(4,2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(2,2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward propagation 수행\n",
        "        o = self.layers(x)\n",
        "        return o\n",
        "    \n",
        "    def predict(self, x):\n",
        "        o = self.forward(x)\n",
        "        y = torch.softmax(o, dim=1)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6oQLEtT8-ND",
        "outputId": "672bc163-b3a7-4a15-8f6a-0be75d0e004a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 입력텐서 타겟 텐서 생성    \n",
        "x = torch.Tensor([[0, 1]])\n",
        "t = torch.LongTensor([0])\n",
        "\n",
        "# 커스텀 모듈 호출\n",
        "model = XOR()\n",
        "\n",
        "# 손실함수\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# 순방향전파\n",
        "y = model(x)\n",
        "\n",
        "# 손실값 계산\n",
        "loss = loss_function(y,t)\n",
        "\n",
        "print(f\"loss value: {loss.item()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss value: 0.33104363083839417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbK-35a18-NE"
      },
      "source": [
        "## nn.AutoGrad\n",
        "\n",
        "PyTorch의 AutoGrad는 Tensor의 미분 자동화를 돕는 패키지다. 각 텐서에는 `requires_grad`라는 속성이 있어서 미분이 필요한 텐서인지 아닌지 확인할 수 있다. 또한 `requires_grad_` 함수를 호출하면 해당 텐서는 미분이 필요한 텐서가 되며, 역전파시 미분을 계산하게 된다.\n",
        "\n",
        "* 함수뒤에 \"\\_\" 표시는 in-place operations 으로써 실행하면 새로운 메모리에 할당하지 않고, 메모리를 차지하고 있는 텐서에 덮어쓰는 형식이다. PyTorch에서는 사용을 권장하고 있지 않다. [관련 링크](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2oldEG48-NF",
        "outputId": "c85d52da-a8ce-4749-e0b7-03f039021dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.FloatTensor([10])\n",
        "\n",
        "print(f\"require gradient? {x.requires_grad}\")\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# requires_grad\n",
        "x.requires_grad_(True)\n",
        "# '_' x의 특성을 바꾼다.\n",
        "print(f\"require gradient? {x.requires_grad}\")\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "require gradient? False\n",
            "tensor([10.])\n",
            "\n",
            "require gradient? True\n",
            "tensor([10.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qNCzQ058-NG"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1SPGm636Na_VrRTHkcBhMOQGMq0CaYAtg\" width=\"640px\" >\n",
        "\n",
        "예제로 계산 그래프를 그려본다.\n",
        "\n",
        "$$\\begin{aligned}\n",
        "c(a, b) &= a + b\\\\\n",
        "d(b) &= 2\\times b + 1\\\\\n",
        "e(c, d) &= c\\times d \n",
        "\\end{aligned} \\\\ \\ \\\\ \\text{where } a=2, b=3$$\n",
        "\n",
        "연산 경로에 미분이 필요한 텐서가 들어가면 자동으로 `requires_grad=True`가 된고, 연산이 진행된 텐서는 `grad_fn` 역전파 함수를 내포하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBnrpYvl8-NH",
        "outputId": "5281e812-9da2-4402-e405-960fae8d8943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.FloatTensor([2]).requires_grad_()\n",
        "b = torch.FloatTensor([3])\n",
        "c = a + b\n",
        "d = 2 * b + 1\n",
        "e = c * d\n",
        "\n",
        "print(f\"require gradient?\")\n",
        "for t, name in zip([a, b, c, d, e], [\"a\", \"b\", \"c\", \"d\", \"e\"]):\n",
        "    print(f\"  - {name}(={t.item()}): {t.requires_grad} \\t/ grad_fn: \\t {t.grad_fn}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "require gradient?\n",
            "  - a(=2.0): True \t/ grad_fn: \t None\n",
            "  - b(=3.0): False \t/ grad_fn: \t None\n",
            "  - c(=5.0): True \t/ grad_fn: \t <AddBackward0 object at 0x7f06a543cfa0>\n",
            "  - d(=7.0): False \t/ grad_fn: \t None\n",
            "  - e(=35.0): True \t/ grad_fn: \t <MulBackward0 object at 0x7f06a543cfa0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwNOexID8-NI"
      },
      "source": [
        "미분을 구하려면 `backward` 함수에 경사를 전달하면 된다. 각 텐서에서 `.grad` 속성을 조회하면 미분값을 확인할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GGcLcCv8-NJ",
        "outputId": "cdf57894-7bc0-44af-bcbb-4a0f2e24de78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gradient = torch.FloatTensor([1.])\n",
        "e.backward(gradient)\n",
        "\n",
        "print(f\"gradient\")\n",
        "for t, name in zip([a, b, c, d, e], [\"a\", \"b\", \"c\", \"d\", \"e\"]):\n",
        "    print(f\"  - {name}: {t.grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient\n",
            "  - a: tensor([7.])\n",
            "  - b: None\n",
            "  - c: None\n",
            "  - d: None\n",
            "  - e: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-c806ec9d3b09>:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(f\"  - {name}: {t.grad}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPOw-uLj8-NK"
      },
      "source": [
        "## torch.optim\n",
        "\n",
        "PyTorch의 최적화 관련된 것은 모두 optim 패키지에 있다. `model.parameters()`는 모델 안에 내포되있는 모든 파라미터를 `generator` 객체를 생성한다. 이를 옵티마이저에게 전달하여 업데이트할 매개변수를 등록한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFECmBIY8-NL"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 입력텐서 타겟 텐서 생성    \n",
        "x = torch.Tensor([[0, 1]])\n",
        "t = torch.LongTensor([0])\n",
        "\n",
        "# 커스텀 모듈 호출\n",
        "model = XOR()\n",
        "\n",
        "# 손실함수\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1) # 최적의 optimzier를 찾아가는 방법\n",
        "\n",
        "# 순방향전파\n",
        "y = model(x)\n",
        "\n",
        "# 손실값 계산\n",
        "loss = loss_function(y, t)\n",
        "\n",
        "# 역전파\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zghElbf9Ojws",
        "outputId": "267d7f11-bafa-4f98-c68c-1048bafaa9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4407,  0.6366],\n",
              "         [-0.3092, -0.1563],\n",
              "         [-0.1584, -0.4085],\n",
              "         [ 0.4569, -0.1494]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.4993, -0.5181, -0.3645, -0.1876], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.1086,  0.3610, -0.3573,  0.1406],\n",
              "         [-0.1545, -0.4260, -0.1394,  0.2492]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.0942, 0.2225], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.3497,  0.0584],\n",
              "         [ 0.3193, -0.2502]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.3200, -0.3378], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhLKQW5N8-NM"
      },
      "source": [
        "옵티마이저의 `.step()` 함수를 호출하면 옵티마이저가 해당 매개변수를 업데이트 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gBkbaoZ8-NN",
        "outputId": "21534ca3-0bab-4ef6-a8a4-69501cade77f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"첫번째 Linear Layer Weight: \")\n",
        "print(model.layers[0].weight)\n",
        "print()\n",
        "print(\"첫번째 Linear Layer Weight의 Gradient: \")\n",
        "print(model.layers[0].weight.grad)\n",
        "print()\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "print(\"첫번째 Linear Layer Weight의 Gradient: \")\n",
        "print(model.layers[0].weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 Linear Layer Weight: \n",
            "Parameter containing:\n",
            "tensor([[-0.4407,  0.6366],\n",
            "        [-0.3092, -0.1563],\n",
            "        [-0.1584, -0.4085],\n",
            "        [ 0.4569, -0.1494]], requires_grad=True)\n",
            "\n",
            "첫번째 Linear Layer Weight의 Gradient: \n",
            "tensor([[ 0.0000,  0.0029],\n",
            "        [ 0.0000,  0.0081],\n",
            "        [-0.0000, -0.0041],\n",
            "        [ 0.0000,  0.0004]])\n",
            "\n",
            "첫번째 Linear Layer Weight의 Gradient: \n",
            "Parameter containing:\n",
            "tensor([[-0.4407,  0.6363],\n",
            "        [-0.3092, -0.1571],\n",
            "        [-0.1584, -0.4081],\n",
            "        [ 0.4569, -0.1494]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iUMmtfE8-NP"
      },
      "source": [
        "경사하강법 $$ W^{(1)}_{new} = W^{(1)}_{old} - \\alpha \\dfrac{\\partial L}{\\partial W^{(1)}}_{old}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAbvAt1G8-NP",
        "outputId": "eb08ecf8-fd73-4d43-a001-6d3ef21dbb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\" w_22 의 파라미터 업데이트: w ={0.3146 - 0.1 * (0.0074): .4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " w_22 의 파라미터 업데이트: w = 0.3139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9icvchVQ8-NR"
      },
      "source": [
        "## XOR 문제 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGvBbL-8-NR",
        "outputId": "e03ed832-7207-4efb-f684-7e57a21ae1cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(70)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # gpu 사용 여부\n",
        "n_step = 10000  # 총 학습 스텝\n",
        "\n",
        "# Data 세트 만들기\n",
        "inputs = torch.FloatTensor([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
        "targets = torch.LongTensor([0, 1, 1, 0])\n",
        "\n",
        "# 모델 생성: gpu를 사용하려면 모델에도 device를 전달해준다.\n",
        "model = XOR().to(device)\n",
        "# 손실함수 정의\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# 옵티마이저 정의\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.7)\n",
        "\n",
        "# GPU를 사용하려면 입력 텐서에도 device를 전달해준다.\n",
        "inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "best_loss = 999\n",
        "# n_step 동안 학습을 진행한다.\n",
        "for step in range(n_step):\n",
        "    # -- 훈련단계 --\n",
        "    train_loss = 0\n",
        "    \n",
        "    # 매개변수 텐서의 grad 정보를 0으로 만든다. model.zero_grad() 로도 가능하다.\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 순방향전파(Forward Propagation)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Loss 계산\n",
        "    loss = loss_function(outputs, targets)\n",
        "    \n",
        "    # 역방향전파(Back Propagation)\n",
        "    loss.backward()\n",
        "    \n",
        "    # 옵티마이저로 매개변수 업데이트\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 훈련단계 손실값 기록(모든 데이터에 손실값의 평균을 합친다.)\n",
        "    train_loss += loss.item()\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        torch.save(model.state_dict(), \"./xor.pt\")\n",
        "    if step % 1000 == 0:\n",
        "        print(f\"[{step+1}] Loss: {train_loss:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Loss: 0.8012\n",
            "[1001] Loss: 0.6842\n",
            "[2001] Loss: 0.0035\n",
            "[3001] Loss: 0.0012\n",
            "[4001] Loss: 0.0007\n",
            "[5001] Loss: 0.0005\n",
            "[6001] Loss: 0.0004\n",
            "[7001] Loss: 0.0003\n",
            "[8001] Loss: 0.0003\n",
            "[9001] Loss: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_2N_ZVORfXq",
        "outputId": "d6a5f473-7c6d-43e8-8248-9b43c96c8f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layers.0.weight',\n",
              "              tensor([[-0.7095, -0.1966],\n",
              "                      [ 1.7193, -2.0518],\n",
              "                      [ 5.7520, -5.7997],\n",
              "                      [ 3.9542, -4.0161]], device='cuda:0')),\n",
              "             ('layers.0.bias',\n",
              "              tensor([-0.6352, -0.9947,  3.0022, -2.2557], device='cuda:0')),\n",
              "             ('layers.2.weight',\n",
              "              tensor([[-0.4618,  2.1358, -5.5186,  4.5091],\n",
              "                      [-0.2662, -1.8281,  4.6862, -4.1580]], device='cuda:0')),\n",
              "             ('layers.2.bias', tensor([ 2.2529, -1.6060], device='cuda:0')),\n",
              "             ('layers.4.weight',\n",
              "              tensor([[-6.4570,  5.3559],\n",
              "                      [ 5.7851, -5.4662]], device='cuda:0')),\n",
              "             ('layers.4.bias', tensor([-0.2816, -0.5573], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BO5I8k8-NT"
      },
      "source": [
        "## 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOMOz7vcXzV0",
        "outputId": "f80a2de2-03db-40f9-9658-8b054cbacc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm5A45UJ8-NT",
        "outputId": "7dd82a8d-668c-4f98-994b-5948b3a8daf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 새로 정의\n",
        "model = XOR()\n",
        "# 모델 불러오기\n",
        "model.load_state_dict(torch.load(\"./xor.pt\", map_location=\"cuda\"))\n",
        "\n",
        "probs = model.predict(inputs.cpu())\n",
        "print(probs)\n",
        "predicts = probs.argmax(1)\n",
        "print(predicts)\n",
        "for prob, pred in zip(probs, predicts):\n",
        "    print(f\"prob: {prob.data}\\t predict {pred}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9977e-01, 2.2552e-04],\n",
            "        [1.6342e-04, 9.9984e-01],\n",
            "        [2.2162e-04, 9.9978e-01],\n",
            "        [9.9983e-01, 1.7327e-04]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0, 1, 1, 0])\n",
            "prob: tensor([9.9977e-01, 2.2552e-04])\t predict 0\n",
            "prob: tensor([1.6342e-04, 9.9984e-01])\t predict 1\n",
            "prob: tensor([2.2162e-04, 9.9978e-01])\t predict 1\n",
            "prob: tensor([9.9983e-01, 1.7327e-04])\t predict 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qRsgUhRrCj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}